# Roadmap for Geospatial Machine Learning in Remote Sensing (MUSA 650)

## Overview

This document outlines the instructors' plans to develop this class over the coming years, in keeping with the evolving fields of remote sensing and machine learning, and based on student feedback and pedagogical practices laid out in material such as [_Teaching Tech Together_](https://teachtogether.tech/en/index.html).

In advance of spring 2025, we update much of the course material to better integrate remote sensing content specific to city planning. We worked to better highlight domain-specific use cases and techniques, as well as to incorporate city planning-related material directly into class assignments. Relateldly, we integrated more tools specific to the remote-sensing domain (e.g., the STAC API via `pystac` and Google Earth Engine via `geemap`), rather than vision models generically. We also updated assignments and course material to better account for the impact that generative AI (e.g., ChatGPT) has had on all aspects of tech instruction. Finally, we structured class assignments to build progressively on each other while also being well-suited to display in student portfolios.

## Spring 2026

By the spring of 2026, we hope to update the course to more thoroughly integrate advance remote sensing tech and tools, e.g., `torchgeo`, `xarray`, and `zarr`, as well as apply them to a broader range of data types (e.g., multispectal and SAR). We will also continue to improve the breadth of clity-planning related topics represented in teh class.

## Spring 2027

By the spring of 2027, we will incorporate material on MLops and data pipelines in order to give students familiarity with the concepts and tools necessary for remote sensing work at scale. We will add an assignment to develop a small, end-to-end remote sensing system, including basic MLops (e.g., model tracking and pipeline management). Relatedly, we will recruit at least one guest speaker to give a lecture specifically on the topic of MLops and remot esensing at scale.
